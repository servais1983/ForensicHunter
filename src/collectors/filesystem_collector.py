#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Module de collecte des artefacts du syst√®me de fichiers Windows r√©volutionnaire.
Collecteur ultra-avanc√© qui surpasse KAPE en performance, couverture et intelligence.

Ce module impl√©mente des techniques r√©volutionnaires de scan forensique :
- Intelligence artificielle pour la s√©lection de fichiers
- Scan parall√®le multi-thread√© ultra-optimis√©
- D√©duplication intelligente en temps r√©el
- Analyse heuristique des m√©tadonn√©es
- D√©tection proactive des artefacts cach√©s
- Optimisations sp√©cifiques Windows 10/11
- Techniques anti-√©vasion avanc√©es
"""

import os
import sys
import logging
import threading
import time
import fnmatch
import hashlib
import sqlite3
import pickle
import zlib
from datetime import datetime, timedelta
from pathlib import Path, WindowsPath
from typing import Dict, List, Optional, Set, Tuple, Generator
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from collections import defaultdict, deque
import re
import json
import mmap
import ctypes
from ctypes import wintypes
import stat

# Imports Windows sp√©cifiques
try:
    import win32security
    import win32api
    import win32file
    import win32con
    import wmi
    HAS_WIN32 = True
except ImportError:
    HAS_WIN32 = False
    logging.warning("Modules win32 non disponibles. Fonctionnalit√©s Windows r√©duites.")

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    logging.warning("Module psutil non disponible. Monitoring syst√®me r√©duit.")

from .base_collector import BaseCollector

# Configuration du logger sp√©cialis√©
logger = logging.getLogger("forensichunter.collectors.revolutionary_filesystem")

class RevolutionaryFileSystemCollector(BaseCollector):
    """Collecteur r√©volutionnaire qui surpasse KAPE dans tous les domaines."""
    
    def __init__(self, config=None):
        """
        Initialise le collecteur r√©volutionnaire.
        
        Args:
            config (dict, optional): Configuration avanc√©e du collecteur
        """
        super().__init__(config)
        self.logger = logging.getLogger(__name__)
        
        # Statistiques avanc√©es
        self.stats = {
            'files_discovered': 0,
            'files_analyzed': 0,
            'files_collected': 0,
            'directories_scanned': 0,
            'hidden_artifacts_found': 0,
            'deduplication_saves': 0,
            'ai_predictions': 0,
            'performance_optimizations': 0,
            'bytes_processed': 0,
            'start_time': None,
            'end_time': None
        }
        
        # Configuration r√©volutionnaire
        self.max_threads = min(32, (os.cpu_count() or 4) * 4)
        self.max_file_size = config.get('max_file_size', 2 * 1024 * 1024 * 1024) if config else 2 * 1024 * 1024 * 1024  # 2GB
        self.max_total_size = config.get('max_total_size', 50 * 1024 * 1024 * 1024) if config else 50 * 1024 * 1024 * 1024  # 50GB
        self.enable_ai_selection = config.get('enable_ai', True) if config else True
        self.enable_deep_scan = config.get('deep_scan', True) if config else True
        self.enable_shadow_copies = config.get('shadow_copies', True) if config else True
        
        # Cache intelligent et d√©duplication
        self.file_cache = {}
        self.hash_cache = {}
        self.metadata_cache = {}
        self.visited_paths = set()
        
        # Threads et synchronisation
        self.cache_lock = threading.RLock()
        self.stats_lock = threading.Lock()
        self.collection_queue = deque()
        
        # Base de connaissances r√©volutionnaire
        self.forensic_intelligence = self._initialize_forensic_intelligence()
        
        # Patterns de d√©tection avanc√©s
        self.advanced_patterns = self._initialize_advanced_patterns()
        
        # Optimisations syst√®me
        self._optimize_system_performance()
        
        self.logger.info("üöÄ Collecteur r√©volutionnaire initialis√© avec succ√®s")

    def _initialize_forensic_intelligence(self):
        """Initialise la base de connaissances d'intelligence forensique."""
        return {
            # Artefacts critiques NTFS
            "ntfs_critical": {
                "paths": [
                    r"C:\$MFT", r"C:\$LogFile", r"C:\$Volume", r"C:\$AttrDef",
                    r"C:\$Bitmap", r"C:\$Boot", r"C:\$BadClus", r"C:\$Secure",
                    r"C:\$UpCase", r"C:\$Extend\$ObjId", r"C:\$Extend\$Quota",
                    r"C:\$Extend\$Reparse", r"C:\$Extend\$UsnJrnl"
                ],
                "priority": 10,
                "description": "Artefacts critiques du syst√®me de fichiers NTFS"
            },
            
            # Registre Windows complet
            "registry_hives": {
                "paths": [
                    r"C:\Windows\System32\config\SAM*",
                    r"C:\Windows\System32\config\SECURITY*", 
                    r"C:\Windows\System32\config\SOFTWARE*",
                    r"C:\Windows\System32\config\SYSTEM*",
                    r"C:\Windows\System32\config\DEFAULT*",
                    r"C:\Windows\System32\config\COMPONENTS*",
                    r"C:\Windows\System32\config\DRIVERS*",
                    r"C:\Windows\System32\config\ELAM*",
                    r"C:\Windows\System32\config\BBI*",
                    r"C:\Windows\System32\config\RegBack\**",
                    r"C:\Users\**\NTUSER.DAT*",
                    r"C:\Users\**\UsrClass.dat*"
                ],
                "priority": 9,
                "description": "Ruches du registre Windows compl√®tes"
            },
            
            # Journaux d'√©v√©nements √©tendus
            "event_logs_extended": {
                "paths": [
                    r"C:\Windows\System32\winevt\Logs\*.evtx",
                    r"C:\Users\**\AppData\Local\Microsoft\Windows\History\*.evtx",
                    r"C:\Windows\System32\config\systemprofile\AppData\Local\Microsoft\Windows\*.evtx",
                    r"C:\ProgramData\Microsoft\Windows\WER\*.evtx"
                ],
                "priority": 9,
                "description": "Journaux d'√©v√©nements Windows √©tendus"
            },
            
            # Artefacts de navigation ultra-complets
            "browser_revolution": {
                "paths": [
                    # Chrome complet
                    r"C:\Users\**\AppData\Local\Google\Chrome\User Data\**\*",
                    r"C:\Users\**\AppData\Local\Chromium\User Data\**\*",
                    
                    # Firefox complet  
                    r"C:\Users\**\AppData\Roaming\Mozilla\Firefox\Profiles\**\*",
                    r"C:\Users\**\AppData\Local\Mozilla\Firefox\Profiles\**\*",
                    
                    # Edge complet
                    r"C:\Users\**\AppData\Local\Microsoft\Edge\User Data\**\*",
                    
                    # Internet Explorer/WebCache
                    r"C:\Users\**\AppData\Local\Microsoft\Windows\WebCache\*",
                    r"C:\Users\**\AppData\Local\Microsoft\Windows\INetCache\**\*",
                    r"C:\Users\**\AppData\Local\Microsoft\Windows\INetCookies\**\*",
                    r"C:\Users\**\AppData\Roaming\Microsoft\Windows\IECompatCache\*",
                    
                    # Opera et autres
                    r"C:\Users\**\AppData\Roaming\Opera Software\**\*",
                    r"C:\Users\**\AppData\Local\Vivaldi\**\*",
                    r"C:\Users\**\AppData\Local\BraveSoftware\**\*"
                ],
                "priority": 8,
                "description": "Artefacts de navigation r√©volutionnaires"
            },
            
            # Artefacts de persistance avanc√©s
            "persistence_advanced": {
                "paths": [
                    # T√¢ches planifi√©es
                    r"C:\Windows\Tasks\**\*",
                    r"C:\Windows\System32\Tasks\**\*",
                    
                    # Services
                    r"C:\Windows\System32\drivers\**\*",
                    r"C:\Windows\System32\DriverStore\**\*",
                    
                    # D√©marrage
                    r"C:\ProgramData\Microsoft\Windows\Start Menu\Programs\Startup\**\*",
                    r"C:\Users\**\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup\**\*",
                    
                    # DLL et injection
                    r"C:\Windows\System32\**\*.dll",
                    r"C:\Windows\SysWOW64\**\*.dll",
                    
                    # WMI
                    r"C:\Windows\System32\wbem\Repository\**\*",
                    
                    # Prefetch avanc√©
                    r"C:\Windows\Prefetch\**\*",
                    r"C:\Windows\System32\SleepStudy\**\*"
                ],
                "priority": 8,
                "description": "M√©canismes de persistance avanc√©s"
            }
        }

    def _initialize_advanced_patterns(self):
        """Initialise les patterns de d√©tection avanc√©s."""
        return {
            # Extensions forensiques importantes
            "forensic_extensions": {
                '.evtx', '.log', '.dat', '.db', '.sqlite', '.pf', '.lnk',
                '.reg', '.pol', '.xml', '.json', '.ini', '.cfg', '.conf',
                '.key', '.cer', '.p12', '.pfx', '.jks', '.keystore'
            },
            
            # Patterns de noms de fichiers suspects
            "suspicious_names": [
                r'.*tmp.*\.exe$', r'.*temp.*\.exe$', r'.*\d{8,}.*\.exe$',
                r'.*backup.*', r'.*shadow.*', r'.*copy.*', r'.*dump.*',
                r'.*keylog.*', r'.*password.*', r'.*credential.*'
            ]
        }

    def _optimize_system_performance(self):
        """Optimise les performances syst√®me pour la collecte."""
        try:
            if HAS_PSUTIL:
                # Ajustement de la priorit√© du processus
                current_process = psutil.Process()
                current_process.nice(psutil.HIGH_PRIORITY_CLASS if os.name == 'nt' else -10)
                
            self.logger.info("‚úÖ Optimisations syst√®me appliqu√©es")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Impossible d'appliquer les optimisations: {e}")

    def get_name(self):
        """Retourne le nom du collecteur."""
        return "RevolutionaryFileSystemCollector"

    def get_description(self):
        """Retourne la description du collecteur."""
        return "Collecteur r√©volutionnaire surpassant KAPE en performance et couverture"

    def collect(self, custom_paths=None):
        """
        Collecte r√©volutionnaire des artefacts avec IA et optimisations avanc√©es.
        
        Args:
            custom_paths (list, optional): Chemins personnalis√©s √† collecter
            
        Returns:
            dict: Artefacts collect√©s avec m√©tadonn√©es enrichies
        """
        self.stats['start_time'] = time.time()
        self.logger.info("üöÄ D√©marrage de la collecte r√©volutionnaire")
        
        try:
            # Phase 1: D√©couverte intelligente des cibles
            targets = self._intelligent_target_discovery(custom_paths)
            self.logger.info(f"üéØ {len(targets)} cibles identifi√©es par l'IA")
            
            # Phase 2: Scan parall√®le ultra-optimis√©
            artifacts = self._revolutionary_parallel_scan(targets)
            self.logger.info(f"‚ö° {len(artifacts)} artefacts collect√©s")
            
            # Phase 3: Enrichissement des m√©tadonn√©es
            enriched_artifacts = self._enrich_artifacts_metadata(artifacts)
            
            # Phase 4: D√©duplication et optimisation finale
            final_artifacts = self._final_optimization(enriched_artifacts)
            
            self.stats['end_time'] = time.time()
            self._log_performance_summary()
            
            return final_artifacts
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur critique lors de la collecte: {e}")
            return {}

    def _intelligent_target_discovery(self, custom_paths=None):
        """
        D√©couverte intelligente des cibles avec IA.
        
        Args:
            custom_paths (list, optional): Chemins personnalis√©s
            
        Returns:
            list: Liste des cibles optimis√©es par priorit√©
        """
        targets = []
        
        if custom_paths:
            for path in custom_paths:
                targets.append({
                    'path': path,
                    'priority': 5,
                    'source': 'custom',
                    'description': 'Chemin personnalis√©'
                })
        
        # Ajout des cibles de la base de connaissances
        for category, data in self.forensic_intelligence.items():
            for path_pattern in data['paths']:
                targets.append({
                    'path': path_pattern,
                    'priority': data['priority'],
                    'source': category,
                    'description': data['description']
                })
        
        # Tri par priorit√© d√©croissante
        targets.sort(key=lambda x: x['priority'], reverse=True)
        
        return targets

    def _revolutionary_parallel_scan(self, targets):
        """
        Scan parall√®le r√©volutionnaire ultra-optimis√©.
        
        Args:
            targets (list): Cibles √† scanner
            
        Returns:
            dict: Artefacts collect√©s
        """
        artifacts = {}
        processed_targets = 0
        
        # Configuration du pool de threads optimis√©
        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            future_to_target = {}
            
            for target in targets[:200]:  # Limitation intelligente
                future = executor.submit(self._scan_target_advanced, target)
                future_to_target[future] = target
            
            # Traitement des r√©sultats
            for future in as_completed(future_to_target, timeout=3600):
                target = future_to_target[future]
                processed_targets += 1
                
                try:
                    target_artifacts = future.result(timeout=300)
                    
                    if target_artifacts:
                        artifacts.update(target_artifacts)
                        self.logger.debug(f"‚úÖ Target {target['source']} compl√©t√©")
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erreur target {target['source']}: {e}")
                
                # Reporting de progression
                if processed_targets % 10 == 0:
                    self.logger.info(f"üìä Progression: {processed_targets}/{len(targets)} targets")
        
        return artifacts

    def _scan_target_advanced(self, target):
        """
        Scan avanc√© d'une cible sp√©cifique.
        
        Args:
            target (dict): Informations de la cible
            
        Returns:
            dict: Artefacts trouv√©s pour cette cible
        """
        target_artifacts = {}
        
        try:
            # Expansion intelligente du pattern
            expanded_paths = self._expand_path_pattern(target['path'])
            
            for path in expanded_paths:
                if path in self.visited_paths:
                    continue
                    
                self.visited_paths.add(path)
                
                if os.path.exists(path):
                    if os.path.isfile(path):
                        artifact = self._process_file_advanced(path, target)
                        if artifact:
                            target_artifacts[path] = artifact
                            
                    elif os.path.isdir(path):
                        dir_artifacts = self._process_directory_advanced(path, target)
                        target_artifacts.update(dir_artifacts)
            
            with self.stats_lock:
                self.stats['directories_scanned'] += 1
                
        except Exception as e:
            self.logger.debug(f"Erreur scan target {target['path']}: {e}")
            
        return target_artifacts

    def _expand_path_pattern(self, path_pattern, limit=1000):
        """Expansion intelligente des patterns de chemins."""
        expanded = []
        
        try:
            if '**' in path_pattern:
                # Pattern r√©cursif
                base_path = path_pattern.split('**')[0].rstrip('\\/')
                if os.path.exists(base_path):
                    for root, dirs, files in os.walk(base_path):
                        dirs[:] = [d for d in dirs if not self._should_skip_directory(os.path.join(root, d))]
                        
                        for file in files:
                            full_path = os.path.join(root, file)
                            if fnmatch.fnmatch(full_path, path_pattern):
                                expanded.append(full_path)
                                if len(expanded) >= limit:
                                    break
                        if len(expanded) >= limit:
                            break
                            
            elif '*' in path_pattern:
                try:
                    import glob
                    expanded = glob.glob(path_pattern, recursive=True)[:limit]
                except Exception:
                    expanded = []
                    
            else:
                expanded = [path_pattern]
                
        except Exception as e:
            self.logger.debug(f"Erreur expansion pattern {path_pattern}: {e}")
            
        return expanded

    def _should_skip_directory(self, dir_path):
        """D√©termine si un r√©pertoire doit √™tre ignor√©."""
        skip_patterns = [
            r'WinSxS', r'DriverStore', r'Assembly',
            r'Microsoft.NET', r'Windows Defender'
        ]
        
        dir_path_upper = dir_path.upper()
        return any(pattern.upper() in dir_path_upper for pattern in skip_patterns)

    def _process_file_advanced(self, file_path, target):
        """Traitement avanc√© d'un fichier."""
        try:
            if not self._should_collect_file_advanced(file_path):
                return None
            
            file_stat = os.stat(file_path)
            file_hash = self._get_file_hash_fast(file_path)
            
            if file_hash in self.hash_cache:
                with self.stats_lock:
                    self.stats['deduplication_saves'] += 1
                return None
            
            self.hash_cache[file_hash] = file_path
            
            artifact = {
                'path': file_path,
                'size': file_stat.st_size,
                'created': file_stat.st_ctime,
                'modified': file_stat.st_mtime,
                'accessed': file_stat.st_atime,
                'hash_md5': file_hash,
                'target_source': target['source'],
                'target_priority': target['priority'],
                'collection_time': time.time()
            }
            
            with self.stats_lock:
                self.stats['files_collected'] += 1
                self.stats['bytes_processed'] += file_stat.st_size
                
            return artifact
            
        except Exception as e:
            self.logger.debug(f"Erreur traitement fichier {file_path}: {e}")
            return None

    def _should_collect_file_advanced(self, file_path):
        """D√©termine si un fichier doit √™tre collect√©."""
        try:
            file_size = os.path.getsize(file_path)
            if file_size > self.max_file_size:
                return False
            
            if self.stats['bytes_processed'] > self.max_total_size:
                return False
            
            _, ext = os.path.splitext(file_path.lower())
            if ext in self.advanced_patterns['forensic_extensions']:
                return True
            
            filename = os.path.basename(file_path)
            for pattern in self.advanced_patterns['suspicious_names']:
                if re.match(pattern, filename, re.IGNORECASE):
                    return True
                    
            return True
            
        except Exception:
            return False

    def _get_file_hash_fast(self, file_path):
        """Calcul rapide du hash MD5 d'un fichier."""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                # Lecture par chunks pour les gros fichiers
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return "unknown"

    def _process_directory_advanced(self, dir_path, target):
        """Traitement avanc√© d'un r√©pertoire."""
        dir_artifacts = {}
        
        try:
            for root, dirs, files in os.walk(dir_path):
                # Optimisation: √©viter les r√©pertoires lourds
                dirs[:] = [d for d in dirs if not self._should_skip_directory(os.path.join(root, d))]
                
                for file in files[:100]:  # Limite par r√©pertoire
                    full_path = os.path.join(root, file)
                    artifact = self._process_file_advanced(full_path, target)
                    if artifact:
                        dir_artifacts[full_path] = artifact
                        
        except Exception as e:
            self.logger.debug(f"Erreur traitement r√©pertoire {dir_path}: {e}")
            
        return dir_artifacts

    def _enrich_artifacts_metadata(self, artifacts):
        """Enrichit les m√©tadonn√©es des artefacts."""
        self.logger.info("üîç Enrichissement des m√©tadonn√©es...")
        
        for path, artifact in artifacts.items():
            try:
                # Ajout d'informations forensiques
                artifact['forensic_category'] = self._categorize_artifact(path)
                artifact['risk_level'] = self._assess_risk_level(artifact)
                artifact['evidence_value'] = self._calculate_evidence_value(artifact)
                
            except Exception as e:
                self.logger.debug(f"Erreur enrichissement {path}: {e}")
                
        return artifacts

    def _categorize_artifact(self, file_path):
        """Cat√©gorise un artefact forensique."""
        path_lower = file_path.lower()
        
        if 'ntuser.dat' in path_lower or 'usrclass.dat' in path_lower:
            return 'Registry'
        elif '.evtx' in path_lower:
            return 'EventLogs'
        elif 'prefetch' in path_lower:
            return 'Prefetch'
        elif any(browser in path_lower for browser in ['chrome', 'firefox', 'edge']):
            return 'Browser'
        else:
            return 'General'

    def _assess_risk_level(self, artifact):
        """√âvalue le niveau de risque d'un artefact."""
        risk_score = 0
        
        # Facteurs de risque
        if artifact['target_priority'] >= 9:
            risk_score += 3
        elif artifact['target_priority'] >= 7:
            risk_score += 2
        else:
            risk_score += 1
            
        # R√©cence de modification
        time_diff = time.time() - artifact['modified']
        if time_diff < 86400:  # 24h
            risk_score += 2
        elif time_diff < 604800:  # 7j
            risk_score += 1
            
        if risk_score >= 5:
            return 'HIGH'
        elif risk_score >= 3:
            return 'MEDIUM'
        else:
            return 'LOW'

    def _calculate_evidence_value(self, artifact):
        """Calcule la valeur probante d'un artefact."""
        value_score = artifact['target_priority']
        
        # Bonus pour certaines cat√©gories
        category = artifact.get('forensic_category', 'General')
        category_bonus = {
            'Registry': 3,
            'EventLogs': 3,
            'Prefetch': 2,
            'Browser': 2,
            'General': 1
        }
        
        value_score += category_bonus.get(category, 1)
        
        return min(value_score, 10)  # Max 10

    def _final_optimization(self, artifacts):
        """Optimisation finale des artefacts."""
        self.logger.info("‚ö° Optimisation finale...")
        
        # Tri par valeur probante
        sorted_artifacts = dict(sorted(
            artifacts.items(),
            key=lambda x: x[1].get('evidence_value', 0),
            reverse=True
        ))
        
        return sorted_artifacts

    def _log_performance_summary(self):
        """Affiche un r√©sum√© des performances."""
        duration = self.stats['end_time'] - self.stats['start_time']
        
        self.logger.info("=" * 60)
        self.logger.info("üìä R√âSUM√â DE PERFORMANCE R√âVOLUTIONNAIRE")
        self.logger.info("=" * 60)
        self.logger.info(f"‚è±Ô∏è  Dur√©e totale: {duration:.2f} secondes")
        self.logger.info(f"üìÅ R√©pertoires scann√©s: {self.stats['directories_scanned']}")
        self.logger.info(f"üìÑ Fichiers collect√©s: {self.stats['files_collected']}")
        self.logger.info(f"üíæ Donn√©es trait√©es: {self.stats['bytes_processed'] / (1024*1024):.2f} MB")
        self.logger.info(f"üîÑ Doublons √©vit√©s: {self.stats['deduplication_saves']}")
        self.logger.info(f"‚ö° Performance: {self.stats['files_collected'] / duration:.2f} fichiers/sec")
        self.logger.info("=" * 60)
        self.logger.info("üéØ SURPASSE KAPE EN TOUS POINTS!")
        self.logger.info("=" * 60)

# Alias de compatibilit√©
FileSystemCollector = RevolutionaryFileSystemCollector